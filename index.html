<!doctype html>
<html lang="id">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Scanner Wajah & Tangan — Gesture to Voice</title>
  <style>
    :root{--bg:#0f1724;--panel:#0b1220;--accent:#06b6d4;--muted:#94a3b8}
    html,body{height:100%;margin:0;font-family:Inter,system-ui,Arial;background:linear-gradient(180deg,#061018 0%, #071829 100%);color:#e6eef6}
    .wrap{max-width:1100px;margin:18px auto;padding:18px}
    header{display:flex;gap:12px;align-items:center}
    h1{font-size:20px;margin:0}
    p.lead{margin:6px 0 0;color:var(--muted)}
    .stage{display:grid;grid-template-columns:1fr 320px;gap:16px;margin-top:16px}
    .card{background:rgba(255,255,255,0.03);padding:12px;border-radius:10px;box-shadow:0 6px 18px rgba(2,6,23,0.6)}
    video{width:100%;height:auto;border-radius:8px;transform:scaleX(-1)}
    canvas{position:absolute;left:0;top:0;transform:scaleX(-1)}
    .preview{position:relative}
    .controls{display:flex;flex-direction:column;gap:8px}
    label{font-size:13px;color:var(--muted)}
    select,input[type="checkbox"]{padding:8px;border-radius:8px;border:1px solid rgba(255,255,255,0.06);background:transparent;color:inherit}
    button{padding:10px;border-radius:8px;border:0;background:var(--accent);color:#012;cursor:pointer}
    ul.legend{padding-left:18px;margin:6px 0}
    footer{margin-top:14px;color:var(--muted);font-size:13px}
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <div>
        <h1>Scanner Wajah & Tangan — Gesture → Voice</h1>
        <p class="lead">Buka camera, sistem akan mendeteksi wajah & tangan. Saat gesture tangan dikenali, suara (bahasa Indonesia) akan diputar.</p>
      </div>
    </header>

    <div class="stage">
      <div class="card preview">
        <div style="position:relative">
          <video id="video" autoplay playsinline></video>
          <canvas id="overlay"></canvas>
        </div>
      </div>

      <aside class="card">
        <div class="controls">
          <label>Bahasa suara</label>
          <select id="voiceLang">
            <option value="id-ID">Indonesia (id-ID)</option>
            <option value="en-US">English (en-US)</option>
          </select>

          <label>Ambang deteksi gesture (frame stabil)</label>
          <select id="stableFrames">
            <option value="6">6 frames</option>
            <option value="10">10 frames</option>
            <option value="3">3 frames (cepat)</option>
          </select>

          <label>
            <input type="checkbox" id="drawLandmarks" checked /> Tampilkan landmark & garis
          </label>

          <button id="toggleCam">Mulai Kamera</button>

          <div>
            <label>Legenda gesture yang didukung</label>
            <ul class="legend">
              <li><b>Fist (0 jari)</b> → "Tangan mengepal"</li>
              <li><b>Open palm (5 jari)</b> → "Halo"</li>
              <li><b>Peace (2 jari)</b> → "Peace / Dua"</li>
              <li><b>Point (1 jari)</b> → "Satu"</li>
              <li><b>Thumbs up</b> → "Bagus!"</li>
            </ul>
          </div>
        </div>
      </aside>
    </div>

    <footer class="card">Catatan: Untuk performa terbaik gunakan Chrome/Edge terbaru. Izinkan akses kamera. Sistem menggunakan heuristik sederhana pada landmark tangan.</footer>
  </div>

  <!-- MediaPipe & helpers via CDN -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>

  <script>
  // --- Element refs ---
  const video = document.getElementById('video');
  const canvas = document.getElementById('overlay');
  const ctx = canvas.getContext('2d');
  const toggleBtn = document.getElementById('toggleCam');
  const drawLandmarksBox = document.getElementById('drawLandmarks');
  const stableFramesSelect = document.getElementById('stableFrames');
  const voiceLang = document.getElementById('voiceLang');

  let camera = null;
  let running = false;
  let lastGesture = null;
  let stableCounter = 0;

  // Resize canvas to match video
  function resizeCanvas(){
    canvas.width = video.videoWidth || 640;
    canvas.height = video.videoHeight || 480;
  }

  // --- Speech helper ---
  function speak(text){
    if(!('speechSynthesis' in window)) return;
    const utter = new SpeechSynthesisUtterance(text);
    // pick voice matching language if possible
    const lang = voiceLang.value || 'id-ID';
    utter.lang = lang;
    // try to select a matching voice
    const voices = speechSynthesis.getVoices() || [];
    const match = voices.find(v=>v.lang && v.lang.startsWith(lang.split('-')[0]));
    if(match) utter.voice = match;
    speechSynthesis.cancel(); // stop previous
    speechSynthesis.speak(utter);
  }

  // --- Gesture recognition heuristics ---
  // Count fingers up (index..pinky) by comparing y of tip vs pip (works when camera upright)
  function countFingers(hand){
    // landmarks: 0..20
    const tips = [8, 12, 16, 20]; // index,indexTip etc
    const pips = [6, 10, 14, 18];
    let count = 0;
    for(let i=0;i<4;i++){
      const tip = hand.landmarks[tips[i]];
      const pip = hand.landmarks[pips[i]];
      if(!tip || !pip) continue;
      // y smaller means finger up (camera mirrored). Use some slack
      if(tip.y < pip.y - 0.02) count++;
    }

    // Thumb: compare tip x vs ip x depending on handedness
    const thumbTip = hand.landmarks[4];
    const thumbIp = hand.landmarks[3];
    if(thumbTip && thumbIp){
      // hand.handedness exists from MediaPipe ("Left"/"Right")
      const handedness = (hand.handedness || 'Right');
      if(handedness.includes('Right')){
        if(thumbTip.x > thumbIp.x + 0.03) count++;
      } else {
        if(thumbTip.x < thumbIp.x - 0.03) count++;
      }
    }
    return count;
  }

  function detectGesture(hand){
    const fingers = countFingers(hand);
    // detect thumbs-up: thumb up + others down
    const thumbTip = hand.landmarks[4];
    const thumbIp = hand.landmarks[3];
    let isThumbUp = false;
    if(thumbTip && thumbIp){
      const handedness = (hand.handedness || 'Right');
      if(handedness.includes('Right')) isThumbUp = (thumbTip.x > thumbIp.x + 0.05) && (thumbTip.y < hand.landmarks[6].y + 0.05);
      else isThumbUp = (thumbTip.x < thumbIp.x - 0.05) && (thumbTip.y < hand.landmarks[6].y + 0.05);
    }

    if(isThumbUp && fingers===1) return 'thumbs_up';
    if(fingers===0) return 'fist';
    if(fingers===5) return 'open_palm';
    if(fingers===2) return 'peace';
    if(fingers===1) return 'point';
    return null;
  }

  // --- MediaPipe setup ---
  const hands = new Hands({locateFile: (file) => {
    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
  }});
  hands.setOptions({
    maxNumHands: 2,
    modelComplexity: 1,
    minDetectionConfidence: 0.6,
    minTrackingConfidence: 0.6
  });

  const faceMesh = new FaceMesh({locateFile:(file)=>`https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
  faceMesh.setOptions({maxNumFaces:1,minDetectionConfidence:0.5,minTrackingConfidence:0.5});

  function onResultsHands(results){
    if(!video.videoWidth) return;
    resizeCanvas();
    ctx.clearRect(0,0,canvas.width,canvas.height);

    // Draw face mesh if exists
    if(results.multiFaceLandmarks && results.multiFaceLandmarks.length){
      for(const landmarks of results.multiFaceLandmarks){
        if(drawLandmarksBox.checked){
          drawConnectors(ctx, landmarks, FACEMESH_TESSELATION, {color: '#8888ff', lineWidth:1});
        }
      }
    }

    // Hands
    if(results.multiHandLandmarks && results.multiHandLandmarks.length){
      for(let i=0;i<results.multiHandLandmarks.length;i++){
        const landmarks = results.multiHandLandmarks[i];
        const handedness = results.multiHandedness && results.multiHandedness[i] ? results.multiHandedness[i].label : 'Right';
        // convert to simpler structure
        const hand = {landmarks: landmarks.map(l=>({x:l.x, y:l.y, z:l.z})), handedness};
        if(drawLandmarksBox.checked){
          drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {color:'#00ffbf', lineWidth:2});
          drawLandmarks(ctx, landmarks, {color:'#ffdd00', lineWidth:1});
        }
        const gesture = detectGesture(hand);
        if(gesture){
          // draw label near wrist (landmark 0)
          const x = landmarks[0].x * canvas.width;
          const y = landmarks[0].y * canvas.height;
          ctx.fillStyle = 'rgba(0,0,0,0.6)';
          ctx.fillRect(x-62,y-28,130,26);
          ctx.fillStyle = '#e6eef6';
          ctx.font = '14px sans-serif';
          ctx.fillText(gesture.replace('_',' '), x-58,y-10);

          // stable detection logic
          if(gesture === lastGesture){
            stableCounter++;
          } else {
            lastGesture = gesture;
            stableCounter = 1;
          }

          const needed = parseInt(stableFramesSelect.value || '6',10);
          if(stableCounter === needed){
            // trigger corresponding speech
            const map = {
              'fist': 'Tangan mengepal',
              'open_palm': 'Halo',
              'peace': 'Peace',
              'point': 'Satu',
              'thumbs_up': 'Bagus!'
            };
            const text = map[gesture] || gesture;
            speak(text);
          }
        }
      }
    } else {
      // no hands -> reset
      lastGesture = null;
      stableCounter = 0;
    }
  }

  // connect faceMesh output to hands renderer for optional face drawing
  hands.onResults(onResultsHands);
  faceMesh.onResults((results)=>{
    // pass face landmarks into the hands.onResults via a fake results object when needed
    hands.send({image: video}); // ensure hands runs; face drawing handled inside hands callback if needed
  });

  // Start/stop camera
  toggleBtn.addEventListener('click', async ()=>{
    if(running){
      stopCamera();
      toggleBtn.textContent = 'Mulai Kamera';
    } else {
      await startCamera();
      toggleBtn.textContent = 'Hentikan Kamera';
    }
  });

  async function startCamera(){
    try{
      const stream = await navigator.mediaDevices.getUserMedia({video:{width:1280,height:720}});
      video.srcObject = stream;
      await video.play();
      resizeCanvas();
      camera = new Camera(video, {onFrame: async ()=>{
        await hands.send({image: video});
        await faceMesh.send({image: video});
      }});
      camera.start();
      running = true;
    } catch(e){
      alert('Gagal mengakses kamera: ' + e.message);
    }
  }

  function stopCamera(){
    if(camera) camera.stop();
    const s = video.srcObject;
    if(s){
      s.getTracks().forEach(t=>t.stop());
      video.srcObject = null;
    }
    running = false;
  }

  // Auto-prepare voices (some browsers require user gesture)
  window.addEventListener('click', ()=>{ speechSynthesis.getVoices(); }, {once:true});

  // Auto start prompt
  // (Don't auto-start camera to avoid permission prompts without user intent.)

  </script>
</body>
</html>
